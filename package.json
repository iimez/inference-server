{
	"name": "lllms",
	"version": "1.0.0-beta.14",
	"description": "Local Large Language Models. Providing node.js tools to run and serve AI models on any machine.",
	"main": "dist/index.js",
	"source": "src/index.ts",
	"types": "dist/index.d.ts",
	"type": "module",
	"license": "MIT",
	"bin": {
		"lllms": "./dist/cli.js"
	},
	"repository": "github:iimez/lllms",
	"bugs": {
		"url": "https://github.com/iimez/lllms/issues"
	},
	"scripts": {
		"upgrade": "npx npm-check-updates -i",
		"reinstall": "rimraf node_modules && npm install",
		"clean": "rimraf dist",
		"download-test-models": "node scripts/download-test-models.js",
		"prebuild": "npm run clean",
		"build": "tsc --build tsconfig.release.json --force && tsc-alias -p tsconfig.release.json",
		"test": "vitest --run",
		"test:pool": "vitest tests/pool.test.ts",
		"test:openai": "vitest tests/openai.test.ts",
		"test:gpt4all": "vitest tests/engines/gpt4all.test.ts",
		"test:llama": "vitest tests/engines/node-llama-cpp.test.ts",
		"test:experiments": "vitest tests/engines/experiments.test.ts",
		"test:server": "vitest tests/server.test.ts",
		"prewatch": "npm run clean",
		"watch": "tsc -w -p tsconfig.release.json",
		"start": "cross-env NODE_ENV=production node dist/standalone.js"
	},
	"keywords": [
		"local ai",
		"inference server",
		"model pool",
		"gpt4all",
		"node-llama-cpp",
		"transformers.js",
		"llama.cpp",
		"chatbot",
		"bot",
		"llm",
		"ai",
		"nlp",
		"openai api"
	],
	"engines": {
		"node": ">=18.16.0"
	},
	"imports": {
		"#lllms/*": "./dist/*"
	},
	"peerDependencies": {
		"@xenova/transformers": "github:xenova/transformers.js#v3",
		"gpt4all": ">=4.0.0",
		"node-llama-cpp": ">=3.0.0-beta.32"
	},
	"peerDependenciesMeta": {
		"node-llama-cpp": {
			"optional": true
		},
		"gpt4all": {
			"optional": true
		},
		"@xenova/transformers": {
			"optional": true
		}
	},
	"dependencies": {
		"@alexanderolsen/libsamplerate-js": "^2.1.1",
		"ajv": "^8.17.1",
		"audio-decode": "^2.2.0",
		"chalk": "^5.3.0",
		"cors": "^2.8.5",
		"express": "^4.19.2",
		"ipull": "^3.5.0",
		"nanoid": "^5.0.7",
		"p-queue": "^8.0.1",
		"pretty-bytes": "^6.1.1",
		"pretty-ms": "^9.0.0"
	},
	"devDependencies": {
		"@types/cors": "^2.8.17",
		"@types/express": "^4.17.21",
		"@types/node": "^20.14.10",
		"@types/supertest": "^6.0.2",
		"@xenova/transformers": "github:xenova/transformers.js#v3",
		"cross-env": "^7.0.3",
		"gpt4all": "^4.0.0",
		"node-llama-cpp": "^3.0.0-beta.38",
		"openai": "^4.52.7",
		"supertest": "^7.0.0",
		"tsc-alias": "^1.8.10",
		"typescript": "^5.5.3",
		"vite-tsconfig-paths": "^4.3.2",
		"vitest": "^2.0.2"
	}
}
